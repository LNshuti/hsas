{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: unmatched \"\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost transformers \"ray[data,train]\" --quiet\n",
    "!pip install \"ray[serve]\n",
    "# Cell 1: Install Necessary Libraries (if not already installed)\n",
    "!pip install --upgrade ray xgboost scikit-learn pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-06 21:39:08,375\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-11-06 21:39:08,716\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-11-06 21:39:09,045\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import ray\n",
    "from ray.data import Dataset, Preprocessor\n",
    "from ray.data.preprocessors import StandardScaler\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from ray.train import Result, ScalingConfig\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "from ray.train import Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data() -> Tuple[Dataset, Dataset, Dataset]:\n",
    "    dataset = ray.data.read_csv(\"s3://anonymous@air-example-data/breast_cancer.csv\")\n",
    "    train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
    "    test_dataset = valid_dataset.drop_columns([\"target\"])\n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(num_workers: int, use_gpu: bool = False) -> Result:\n",
    "    train_dataset, valid_dataset, _ = prepare_data()\n",
    "\n",
    "    # Scale some random columns\n",
    "    columns_to_scale = [\"mean radius\", \"mean texture\"]\n",
    "    preprocessor = StandardScaler(columns=columns_to_scale)\n",
    "    train_dataset = preprocessor.fit_transform(train_dataset)\n",
    "    valid_dataset = preprocessor.transform(valid_dataset)\n",
    "\n",
    "    # XGBoost specific params\n",
    "    params = {\n",
    "        \"tree_method\": \"approx\",\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "    }\n",
    "\n",
    "    trainer = XGBoostTrainer(\n",
    "        scaling_config=ScalingConfig(num_workers=num_workers, use_gpu=use_gpu),\n",
    "        label_column=\"target\",\n",
    "        params=params,\n",
    "        datasets={\"train\": train_dataset, \"valid\": valid_dataset},\n",
    "        num_boost_round=100,\n",
    "        metadata = {\"preprocessor_pkl\": preprocessor.serialize()}\n",
    "    )\n",
    "    result = trainer.fit()\n",
    "    print(result.metrics)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predict:\n",
    "\n",
    "    def __init__(self, checkpoint: Checkpoint):\n",
    "        self.model = XGBoostTrainer.get_model(checkpoint)\n",
    "        self.preprocessor = Preprocessor.deserialize(checkpoint.get_metadata()[\"preprocessor_pkl\"])\n",
    "\n",
    "    def __call__(self, batch: pd.DataFrame) -> pd.DataFrame:\n",
    "        preprocessed_batch = self.preprocessor.transform_batch(batch)\n",
    "        dmatrix = xgboost.DMatrix(preprocessed_batch)\n",
    "        return {\"predictions\": self.model.predict(dmatrix)}\n",
    "\n",
    "\n",
    "def predict_xgboost(result: Result):\n",
    "    _, _, test_dataset = prepare_data()\n",
    "\n",
    "    scores = test_dataset.map_batches(\n",
    "        Predict, \n",
    "        fn_constructor_args=[result.checkpoint], \n",
    "        concurrency=1, \n",
    "        batch_format=\"pandas\"\n",
    "    )\n",
    "    \n",
    "    predicted_labels = scores.map_batches(lambda df: (df > 0.5).astype(int), batch_format=\"pandas\")\n",
    "    predicted_labels.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 21:39:09,175\tINFO worker.py:1631 -- Connecting to existing Ray cluster at address: 127.0.0.1:64780...\n",
      "[2024-11-06 21:39:14,188 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:39:44,219 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:39:50,232 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:40:20,263 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:40:26,273 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:40:56,303 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:41:02,317 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:41:32,351 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:41:38,360 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:42:08,389 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:42:14,399 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:42:44,428 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:42:50,436 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:43:20,464 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:43:26,466 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:43:56,497 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:44:02,509 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:44:32,595 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:44:38,604 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:45:08,634 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:45:14,644 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:45:44,672 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:45:50,684 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:46:20,713 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:46:26,722 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:46:56,751 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:47:02,764 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:47:32,795 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:47:38,805 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:48:08,835 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:48:14,848 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:48:44,879 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:48:50,889 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:49:20,919 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:49:26,932 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:49:56,962 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:50:02,973 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:50:33,003 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 21:50:39,016 E 35024 3714882] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 21:51:09,045 W 35024 3714882] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "2024-11-06 21:51:10,051\tINFO worker.py:1781 -- Failed to connect to the default Ray cluster address at 127.0.0.1:64780. This is most likely due to a previous Ray instance that has since crashed. To reset the default address to connect to, run `ray stop` or restart Ray with `ray start`.\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/_private/worker.py:1772\u001b[0m, in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, labels, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, logging_config, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1772\u001b[0m     _global_node \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_private\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1773\u001b[0m \u001b[43m        \u001b[49m\u001b[43mray_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshutdown_at_exit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspawn_reaper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnect_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mConnectionError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/_private/node.py:159\u001b[0m, in \u001b[0;36mNode.__init__\u001b[0;34m(self, ray_params, head, shutdown_at_exit, spawn_reaper, connect_only, default_worker, ray_init_cluster)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_ip_port(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress)\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_gcs_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Register the temp dir.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/_private/node.py:770\u001b[0m, in \u001b[0;36mNode._init_gcs_client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    771\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnect to\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GCS. Last \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    772\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnection error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_ex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    773\u001b[0m         )\n\u001b[1;32m    775\u001b[0m ray\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39minternal_kv\u001b[38;5;241m.\u001b[39m_initialize_internal_kv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gcs_client)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to connect to GCS. Last connection error: Traceback (most recent call last):\n  File \"/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/_private/node.py\", line 733, in _init_gcs_client\n    client = GcsClient(\n             ^^^^^^^^^^\n  File \"python/ray/_raylet.pyx\", line 2705, in ray._raylet.GcsClient.__cinit__\n  File \"python/ray/includes/gcs_client.pxi\", line 64, in ray._raylet.NewGcsClient.standalone\n  File \"python/ray/includes/common.pxi\", line 114, in ray._raylet.check_status_timeout_as_rpc_error\nray.exceptions.RpcError: Timed out while waiting for GCS to become available.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ray\u001b[38;5;241m.\u001b[39mis_initialized():\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_reinit_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Starts Ray locally\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Cell 3: Import Libraries\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/_private/worker.py:1788\u001b[0m, in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, labels, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, logging_config, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gcs_address \u001b[38;5;241m==\u001b[39m ray\u001b[38;5;241m.\u001b[39m_private\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mread_ray_address(_temp_dir):\n\u001b[1;32m   1781\u001b[0m             logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   1782\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to connect to the default Ray cluster address at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1783\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgcs_address\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is most likely due to a previous Ray \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`ray start`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1787\u001b[0m             )\n\u001b[0;32m-> 1788\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;66;03m# Log a message to find the Ray address that we connected to and the\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;66;03m# dashboard URL.\u001b[39;00m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ray_constants\u001b[38;5;241m.\u001b[39mRAY_OVERRIDE_DASHBOARD_URL \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "\u001b[0;31mConnectionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cell 2: Initialize Ray\n",
    "import ray\n",
    "\n",
    "if not ray.is_initialized():\n",
    "    ray.init(ignore_reinit_error=True)  # Starts Ray locally\n",
    "\n",
    "# Cell 3: Import Libraries\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (2.38.0)\n",
      "Requirement already satisfied: xgboost in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (2.1.4)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: click>=7.0 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from ray) (8.1.7)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from ray) (3.16.1)\n",
      "Requirement already satisfied: jsonschema in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from ray) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from ray) (1.1.0)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from ray) (24.1)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from ray) (3.20.3)\n",
      "Requirement already satisfied: pyyaml in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from ray) (6.0.2)\n",
      "Requirement already satisfied: aiosignal in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from ray) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from ray) (1.4.1)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from ray) (2.32.3)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from xgboost) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from jsonschema->ray) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from jsonschema->ray) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from jsonschema->ray) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from jsonschema->ray) (0.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from requests->ray) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from requests->ray) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from requests->ray) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/hsas/lib/python3.11/site-packages (from requests->ray) (2024.8.30)\n",
      "Using cached pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.4\n",
      "    Uninstalling pandas-2.1.4:\n",
      "      Successfully uninstalled pandas-2.1.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "modin 0.25.1 requires pandas<2.2,>=2.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pandas-2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 20:40:48,218\tINFO worker.py:1631 -- Connecting to existing Ray cluster at address: 127.0.0.1:64780...\n",
      "[2024-11-06 20:40:53,226 E 20532 3648458] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 20:41:23,255 W 20532 3648458] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 20:41:29,264 E 20532 3648458] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 20:41:59,294 W 20532 3648458] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 20:42:05,306 E 20532 3648458] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n",
      "[2024-11-06 20:42:35,333 W 20532 3648458] gcs_client.cc:178: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-11-06 20:42:41,341 E 20532 3648458] gcs_rpc_client.h:179: Failed to connect to GCS at address 127.0.0.1:64780 within 5 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Define Functions\n",
    "@ray.remote\n",
    "class Predict:\n",
    "    def __init__(self, checkpoint):\n",
    "        # Initialize your model and preprocessor here\n",
    "        self.model = xgboost.Booster()\n",
    "        self.model.load_model(checkpoint)\n",
    "        # self.preprocessor = YourPreprocessor()  # Define your preprocessor\n",
    "\n",
    "    def transform_batch(self, batch):\n",
    "        # Implement your preprocessing here\n",
    "        # preprocessed_batch = self.preprocessor.transform(batch)\n",
    "        return batch  # Replace with actual preprocessing\n",
    "\n",
    "    def predict(self, batch):\n",
    "        preprocessed_batch = self.transform_batch(batch)\n",
    "        dmatrix = xgboost.DMatrix(preprocessed_batch)\n",
    "        return {\"predictions\": self.model.predict(dmatrix)}\n",
    "\n",
    "def train_xgboost(num_workers: int, use_gpu: bool = False) -> ray.actor.ActorHandle:\n",
    "    # Prepare data\n",
    "    train_dataset, valid_dataset, _ = prepare_data()\n",
    "\n",
    "    # Initialize the Predictor actor\n",
    "    predictor = Predict.remote('path_to_model_checkpoint')  # Replace with actual path\n",
    "\n",
    "    # Example prediction (replace with your actual training logic)\n",
    "    batch = train_dataset.take(10)  # Example batch\n",
    "    result = ray.get(predictor.predict.remote(batch))\n",
    "    print(result)\n",
    "    return predictor\n",
    "\n",
    "# Cell 5: Train the Model\n",
    "result = train_xgboost(num_workers=2, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 23:03:40,300\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-11-05_21-43-13_393763_11030/logs/ray-data\n",
      "2024-11-05 23:03:40,300\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadCSV]\n",
      "                                                                                                 \n",
      "✔️  Dataset execution finished in 0.83 seconds: 100%|██████████| 569/569 [00:00<00:00, 686 row/s]\n",
      "\n",
      "- ReadCSV->SplitBlocks(16): Tasks: 0; Queued blocks: 0; Resources: 0.0 CPU, 94.2KB object store: : 569 row [00:00, 688 row/s]\n",
      "2024-11-05 23:03:41,137\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-11-05_21-43-13_393763_11030/logs/ray-data\n",
      "2024-11-05 23:03:41,137\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadCSV]\n",
      "                                                                                                 \n",
      "✔️  Dataset execution finished in 0.63 seconds: 100%|██████████| 569/569 [00:00<00:00, 902 row/s]\n",
      "\n",
      "- ReadCSV->SplitBlocks(16): Tasks: 0; Queued blocks: 0; Resources: 0.0 CPU, 17.0KB object store: : 569 row [00:00, 903 row/s]\n",
      "2024-11-05 23:03:41,780\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-11-05_21-43-13_393763_11030/logs/ray-data\n",
      "2024-11-05 23:03:41,780\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> ActorPoolMapOperator[MapBatches(drop_columns)->MapBatches(Predict)] -> TaskPoolMapOperator[MapBatches(<lambda>)] -> LimitOperator[limit=20]\n",
      "Running 0: 0.00 row [00:00, ? row/s]\n",
      "\u001b[A\n",
      "\n",
      "                                                                                                    \n",
      "\u001b[A                                                                         \n",
      "\n",
      "\u001b[A\u001b[A                                             \n",
      "\n",
      "\n",
      "✔️  Dataset execution finished in 0.97 seconds: 100%|██████████| 20.0/20.0 [00:00<00:00, 20.5 row/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A                                                                                                                                                                                      \n",
      "\n",
      "\u001b[A\u001b[A                                             \n",
      "\n",
      "\n",
      "- MapBatches(drop_columns)->MapBatches(Predict): Tasks: 0; Queued blocks: 0; Resources: 0.0 CPU, 280.0B object store; [locality off]: 100%|██████████| 171/171 [00:00<00:00, 2.46k row/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                                                                                                                         \n",
      "\n",
      "\n",
      "- MapBatches(<lambda>): Tasks: 2; Queued blocks: 0; Resources: 2.0 CPU, 2.0KB object store: 100%|██████████| 136/136 [00:00<00:00, 1.84k row/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "- limit=20: Tasks: 0; Queued blocks: 3; Resources: 0.0 CPU, 292.0B object store: 100%|██████████| 20.0/20.0 [00:00<00:00, 261 row/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 0}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 0}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 0}\n",
      "{'predictions': 0}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_xgboost(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name: model.py\n",
    "from transformers import pipeline\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self):\n",
    "        # Load model\n",
    "        self.model = pipeline(\"translation_en_to_fr\", model=\"t5-small\")\n",
    "\n",
    "    def translate(self, text: str) -> str:\n",
    "        # Run inference\n",
    "        model_output = self.model(text)\n",
    "\n",
    "        # Post-process output to return only the translation text\n",
    "        translation = model_output[0][\"translation_text\"]\n",
    "\n",
    "        return translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'grpc'. You can run `pip install \"ray[serve]\"` to install all Ray Serve dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serve\n\u001b[1;32m      3\u001b[0m translator \u001b[38;5;241m=\u001b[39m Translator()\n\u001b[1;32m      5\u001b[0m translation \u001b[38;5;241m=\u001b[39m translator\u001b[38;5;241m.\u001b[39mtranslate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello world!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/serve/__init__.py:30\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     26\u001b[0m     e\u001b[38;5;241m.\u001b[39mmsg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You can run `pip install \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mray[serve]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` to install all Ray Serve\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dependencies.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m     )\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Setup default ray.serve logger to ensure all serve module logs are captured.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m configure_default_serve_logger()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/serve/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworker\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_default_serve_logger\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m         Application,\n\u001b[1;32m      7\u001b[0m         Deployment,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m         status,\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m batch\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/serve/_private/logging_utils.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mray_logging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoreContextFilter\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mray_logging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformatters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JSONFormatter\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ServeComponentType\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     14\u001b[0m     RAY_SERVE_ENABLE_CPU_PROFILING,\n\u001b[1;32m     15\u001b[0m     RAY_SERVE_ENABLE_JSON_LOGGING,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     SERVE_LOGGER_NAME,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_component_file_name\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/serve/_private/common.py:23\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerated\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     DeploymentStatusTrigger \u001b[38;5;28;01mas\u001b[39;00m DeploymentStatusTriggerProto,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerated\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StatusOverview \u001b[38;5;28;01mas\u001b[39;00m StatusOverviewProto\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrpc_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RayServegRPCContext\n\u001b[1;32m     25\u001b[0m REPLICA_ID_FULL_ID_STR_PREFIX \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSERVE_REPLICA::\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m(frozen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDeploymentID\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/serve/grpc_util.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Tuple\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgrpc\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PublicAPI\n\u001b[1;32m      8\u001b[0m \u001b[38;5;129m@PublicAPI\u001b[39m(stability\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRayServegRPCContext\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'grpc'. You can run `pip install \"ray[serve]\"` to install all Ray Serve dependencies."
     ]
    }
   ],
   "source": [
    "from ray import serve\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "translation = translator.translate(\"Hello world!\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from fastapi import FastAPI\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "app = FastAPI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(num_replicas=2, ray_actor_options={\"num_cpus\": 0.2, \"num_gpus\": 0})\n",
    "@serve.ingress(app)\n",
    "class Translator:\n",
    "    def __init__(self):\n",
    "        # Load model\n",
    "        self.model = pipeline(\"translation_en_to_fr\", model=\"t5-small\")\n",
    "\n",
    "    @app.post(\"/\")\n",
    "    def translate(self, text: str) -> str:\n",
    "        # Run inference\n",
    "        model_output = self.model(text)\n",
    "\n",
    "        # Post-process output to return only the translation text\n",
    "        translation = model_output[0][\"translation_text\"]\n",
    "\n",
    "        return translation\n",
    "\n",
    "translator_app = Translator.bind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'grpc'. You can run `pip install \"ray[serve]\"` to install all Ray Serve dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# File name: model_client.py\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serve\n\u001b[1;32m      5\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://127.0.0.1:8000/\u001b[39m\u001b[38;5;124m\"\u001b[39m, params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello world!\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m      6\u001b[0m french_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/serve/__init__.py:30\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     26\u001b[0m     e\u001b[38;5;241m.\u001b[39mmsg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You can run `pip install \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mray[serve]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` to install all Ray Serve\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dependencies.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m     )\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Setup default ray.serve logger to ensure all serve module logs are captured.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m configure_default_serve_logger()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/serve/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworker\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_default_serve_logger\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m         Application,\n\u001b[1;32m      7\u001b[0m         Deployment,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m         status,\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m batch\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/serve/_private/logging_utils.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mray_logging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoreContextFilter\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mray_logging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformatters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JSONFormatter\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ServeComponentType\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     14\u001b[0m     RAY_SERVE_ENABLE_CPU_PROFILING,\n\u001b[1;32m     15\u001b[0m     RAY_SERVE_ENABLE_JSON_LOGGING,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     SERVE_LOGGER_NAME,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_component_file_name\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/serve/_private/common.py:23\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerated\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     DeploymentStatusTrigger \u001b[38;5;28;01mas\u001b[39;00m DeploymentStatusTriggerProto,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerated\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StatusOverview \u001b[38;5;28;01mas\u001b[39;00m StatusOverviewProto\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrpc_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RayServegRPCContext\n\u001b[1;32m     25\u001b[0m REPLICA_ID_FULL_ID_STR_PREFIX \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSERVE_REPLICA::\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m(frozen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDeploymentID\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hsas/lib/python3.11/site-packages/ray/serve/grpc_util.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Tuple\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgrpc\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PublicAPI\n\u001b[1;32m      8\u001b[0m \u001b[38;5;129m@PublicAPI\u001b[39m(stability\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRayServegRPCContext\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'grpc'. You can run `pip install \"ray[serve]\"` to install all Ray Serve dependencies."
     ]
    }
   ],
   "source": [
    "# File name: model_client.py\n",
    "import requests\n",
    "from ray import serve\n",
    "\n",
    "response = requests.post(\"http://127.0.0.1:8000/\", params={\"text\": \"Hello world!\"})\n",
    "french_text = response.json()\n",
    "\n",
    "print(french_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from starlette.requests import Request\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL_PATH = os.path.join(tempfile.gettempdir(), \"mnist_model.h5\")\n",
    "\n",
    "def train_and_save_model():\n",
    "    # Load mnist dataset\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "    # Train a simple neural net model\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])\n",
    "    model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "    model.evaluate(x_test, y_test, verbose=2)\n",
    "    model.summary()\n",
    "\n",
    "    # Save the model in h5 format in local file system\n",
    "    model.save(TRAINED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TRAINED_MODEL_PATH):\n",
    "    train_and_save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'serve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;129m@serve\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTFMnistModel\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'serve' is not defined"
     ]
    }
   ],
   "source": [
    "@serve.deployment\n",
    "class TFMnistModel:\n",
    "    def __init__(self, model_path: str):\n",
    "        import tensorflow as tf\n",
    "\n",
    "        self.model_path = model_path\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    async def __call__(self, starlette_request: Request) -> Dict:\n",
    "        # Step 1: transform HTTP request -> tensorflow input\n",
    "        # Here we define the request schema to be a json array.\n",
    "        input_array = np.array((await starlette_request.json())[\"array\"])\n",
    "        reshaped_array = input_array.reshape((1, 28, 28))\n",
    "\n",
    "        # Step 2: tensorflow input -> tensorflow output\n",
    "        prediction = self.model(reshaped_array)\n",
    "\n",
    "        # Step 3: tensorflow output -> web output\n",
    "        return {\"prediction\": prediction.numpy().tolist(), \"file\": self.model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(\n",
    "    \"http://localhost:8000/\", json={\"array\": np.random.randn(28 * 28).tolist()}\n",
    ")\n",
    "print(resp.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
